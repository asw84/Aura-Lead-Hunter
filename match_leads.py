"""
Aura Lead Hunter - AI Matching Engine
======================================
–°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ä–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª–µ–π –∏ –±–∞–π–µ—Ä–æ–≤ –ø–æ:
- –í–µ—Ä—Ç–∏–∫–∞–ª—å (Dating, Crypto, Gambling, Nutra)
- –ì–ï–û (Tier 1, Tier 2, Asian, EU)
- –û–ø—ã—Ç –∏ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞ —Ç—Ä–∞—Ñ–∏–∫–∞

–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –æ–±–µ–∏—Ö —Å—Ç–æ—Ä–æ–Ω.

Usage:
    py match_leads.py
"""

import csv
import re
from datetime import datetime
from pathlib import Path
from dataclasses import dataclass, field
from typing import List, Optional, Dict, Any


@dataclass
class Employer:
    """–†–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª—å/–¢–∏–º–ª–∏–¥."""
    contact: str
    score: int
    category: str
    reason: str
    language: str  # üá∑üá∫ RU / üá∫üá¶ UA
    vertical: str  # Dating, Crypto, Gambling, General
    geo: List[str] = field(default_factory=list)
    conditions: str = ""  # 70%, —Ñ–∏–∫—Å, —Å—Ç–∞–≤–∫–∞


@dataclass 
class Buyer:
    """–ë–∞–π–µ—Ä/–¢—Ä–∞—Ñ–∏–∫ –ø–æ–∫—É–ø–∞—Ç–µ–ª—å."""
    contact: str
    user_id: int
    display_name: str
    score: int
    category: str
    reason_en: str
    reason_ru: str
    bio: str
    source_chat: str
    vertical: str = "General"
    geo: List[str] = field(default_factory=list)
    traffic_type: str = ""  # FB, TT, Google
    volume: str = ""  # 2M daily, etc.


@dataclass
class Match:
    """–ú—ç—Ç—á –º–µ–∂–¥—É —Ä–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª–µ–º –∏ –±–∞–π–µ—Ä–æ–º."""
    employer: Employer
    buyer: Buyer
    match_score: int  # 1-100
    match_reason: str
    message_to_employer: str
    message_to_buyer: str


def detect_vertical(text: str) -> str:
    """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –≤–µ—Ä—Ç–∏–∫–∞–ª—å –ø–æ —Ç–µ–∫—Å—Ç—É."""
    text_lower = text.lower()
    
    if any(kw in text_lower for kw in ['dating', '–¥–µ–π—Ç–∏–Ω–≥', '–∑–Ω–∞–∫–æ–º—Å—Ç–≤', 'date']):
        return 'Dating'
    elif any(kw in text_lower for kw in ['crypto', '–∫—Ä–∏–ø—Ç–æ', 'web3', 'nft', 'defi', 'ton', 'bitcoin']):
        return 'Crypto'
    elif any(kw in text_lower for kw in ['gambling', '–≥–µ–º–±–ª', 'casino', '–∫–∞–∑–∏–Ω–æ', 'igaming', 'betting', 'ggbet', 'slots']):
        return 'Gambling'
    elif any(kw in text_lower for kw in ['nutra', '–Ω—É—Ç—Ä–∞', 'health', '–∑–¥–æ—Ä–æ–≤', 'weight', 'diet']):
        return 'Nutra'
    elif any(kw in text_lower for kw in ['forex', 'trading', '—Ç—Ä–µ–π–¥–∏–Ω–≥', 'cfd']):
        return 'Forex'
    elif any(kw in text_lower for kw in ['gaming', 'game', 'cpi', 'mobile']):
        return 'Gaming'
    else:
        return 'General'


def detect_geo(text: str) -> List[str]:
    """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å GEO –ø–æ —Ç–µ–∫—Å—Ç—É."""
    text_lower = text.lower()
    geos = []
    
    # Tier 1
    if any(kw in text_lower for kw in ['tier 1', 'tier1', 'usa', 'uk', 'canada', 'australia', '–≥–µ—Ä–º–∞–Ω–∏—è', 'germany', 'france']):
        geos.append('Tier1')
    
    # Tier 2
    if any(kw in text_lower for kw in ['tier 2', 'tier2', 'brazil', 'brasil', 'mexico', 'poland', 'spain', 'italy']):
        geos.append('Tier2')
    
    # Asian
    if any(kw in text_lower for kw in ['asian', 'asia', 'india', 'indian', 'indonesia', 'vietnam', 'thailand', '–∞–∑–∏—è', '–∏–Ω–¥–∏—è', '–∏–Ω–¥–æ–Ω–µ–∑–∏—è']):
        geos.append('Asia')
    
    # CIS/RU
    if any(kw in text_lower for kw in ['cis', 'russia', 'russian', '—Å–Ω–≥', '—Ä–æ—Å—Å–∏—è', 'ukraine', 'ua', '–∫–∞–∑–∞—Ö—Å—Ç–∞–Ω', 'belarus']):
        geos.append('CIS')
    
    # Latam
    if any(kw in text_lower for kw in ['latam', 'latin', 'brazil', 'argentina', 'chile', 'peru', 'colombia']):
        geos.append('Latam')
    
    return geos if geos else ['Worldwide']


def detect_traffic_type(text: str) -> str:
    """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø —Ç—Ä–∞—Ñ–∏–∫–∞."""
    text_lower = text.lower()
    types = []
    
    if any(kw in text_lower for kw in ['fb', 'facebook', 'meta']):
        types.append('FB')
    if any(kw in text_lower for kw in ['tt', 'tiktok', 'tik tok']):
        types.append('TT')
    if any(kw in text_lower for kw in ['google', 'uac', 'adwords']):
        types.append('Google')
    if any(kw in text_lower for kw in ['push', 'native', 'pop']):
        types.append('Push/Pop')
    if any(kw in text_lower for kw in ['seo', 'organic']):
        types.append('SEO')
    if any(kw in text_lower for kw in ['email', 'smtp']):
        types.append('Email')
    
    return '/'.join(types) if types else 'Mixed'


def detect_volume(text: str) -> str:
    """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –æ–±—ä—ë–º —Ç—Ä–∞—Ñ–∏–∫–∞."""
    # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Ç–∏–ø–∞ 2M, 50k, 30-50 FD
    patterns = [
        r'(\d+[MmKk]+)\s*(daily|–≤ –¥–µ–Ω—å|traffic|—Ç—Ä–∞—Ñ–∏–∫)?',
        r'(\d+-\d+)\s*(fd|—Ñ–¥|–¥–µ–ø–æ–∑–∏—Ç|leads|–ª–∏–¥–æ–≤)',
        r'(\d+)\s*(leads|–ª–∏–¥–æ–≤|–∫–æ–Ω–≤–µ—Ä—Ç|conversions)\s*(daily|–≤ –¥–µ–Ω—å)?'
    ]
    
    for pattern in patterns:
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            return match.group(0)
    
    return ""


def detect_conditions(text: str) -> str:
    """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —É—Å–ª–æ–≤–∏—è —Ä–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª—è."""
    conditions = []
    
    # –ü—Ä–æ—Ü–µ–Ω—Ç
    pct_match = re.search(r'(\d+)\s*%', text)
    if pct_match:
        conditions.append(f"{pct_match.group(1)}%")
    
    # –§–∏–∫—Å/—Å—Ç–∞–≤–∫–∞
    if any(kw in text.lower() for kw in ['—Ñ–∏–∫—Å', 'fix', '—Å—Ç–∞–≤–∫–∞', 'rate', 'salary']):
        conditions.append("–§–∏–∫—Å")
    
    # –ë–æ–Ω—É—Å—ã
    if any(kw in text.lower() for kw in ['–±–æ–Ω—É—Å', 'bonus', '–ø—Ä–µ–º–∏—è', 'prize']):
        conditions.append("–ë–æ–Ω—É—Å—ã")
    
    # –û—Ç–ø—É—Å–∫
    if any(kw in text.lower() for kw in ['–æ—Ç–ø—É—Å–∫', 'vacation', '–≤—ñ–¥–ø—É—Å—Ç–∫–∞']):
        conditions.append("–û—Ç–ø—É—Å–∫")
    
    return ", ".join(conditions) if conditions else "–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ"


def parse_employers(filepath: Path) -> List[Employer]:
    """–ü–∞—Ä—Å–∏–Ω–≥ —Ñ–∞–π–ª–∞ —Ä–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª–µ–π."""
    employers = []
    
    with open(filepath, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # –ù–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç: # @contact | 9/10 | üá∫üá¶ UA | category | reason
    pattern = r'#\s*(@\S+|ID:\d+)\s*\|\s*(\d+)/10\s*\|\s*(üá∫üá¶ UA|üá∑üá∫ RU)\s*\|\s*(\S+)\s*\|\s*(.+)'
    matches = re.findall(pattern, content)
    
    # Fallback: —Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç –±–µ–∑ —è–∑—ã–∫–∞
    if not matches:
        pattern = r'#\s*(@\S+|ID:\d+)\s*\|\s*(\d+)/10\s*\|\s*(\S+)\s*\|\s*(.+)'
        old_matches = re.findall(pattern, content)
        for match in old_matches:
            contact, score, category, reason = match
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —è–∑—ã–∫ –ø–æ —Å–∏–º–≤–æ–ª–∞–º
            ua_chars = set('—ñ—ó—î“ë')
            language = 'üá∫üá¶ UA' if any(c in reason.lower() for c in ua_chars) else 'üá∑üá∫ RU'
            
            employer = Employer(
                contact=contact.strip(),
                score=int(score),
                category=category.strip(),
                reason=reason.strip(),
                language=language,
                vertical=detect_vertical(reason),
                geo=detect_geo(reason),
                conditions=detect_conditions(reason)
            )
            employers.append(employer)
        return employers
    
    for match in matches:
        contact, score, language, category, reason = match
        
        employer = Employer(
            contact=contact.strip(),
            score=int(score),
            category=category.strip(),
            reason=reason.strip(),
            language=language.strip(),
            vertical=detect_vertical(reason),
            geo=detect_geo(reason),
            conditions=detect_conditions(reason)
        )
        employers.append(employer)
    
    return employers


def parse_buyers(filepath: Path) -> List[Buyer]:
    """–ü–∞—Ä—Å–∏–Ω–≥ CSV —Å –±–∞–π–µ—Ä–∞–º–∏."""
    buyers = []
    
    with open(filepath, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        
        for row in reader:
            try:
                score = int(row.get('score', 0))
                if score < 6:  # –¢–æ–ª—å–∫–æ score 6+
                    continue
                
                category = row.get('category', '')
                if category not in ['traffic_buyer', 'marketing_pro', 'influencer']:
                    continue  # –¢–æ–ª—å–∫–æ —Ä–µ–∞–ª—å–Ω—ã–µ –±–∞–π–µ—Ä—ã
                
                full_text = f"{row.get('ai_summary_en', '')} {row.get('ai_summary_ru', '')} {row.get('message_preview', '')} {row.get('bio', '')}"
                
                buyer = Buyer(
                    contact=row.get('telegram_handle', f"ID:{row.get('user_id', '')}"),
                    user_id=int(row.get('user_id', 0)),
                    display_name=row.get('display_name', ''),
                    score=score,
                    category=category,
                    reason_en=row.get('ai_summary_en', ''),
                    reason_ru=row.get('ai_summary_ru', ''),
                    bio=row.get('bio', ''),
                    source_chat=row.get('source_chat', ''),
                    vertical=detect_vertical(full_text),
                    geo=detect_geo(full_text),
                    traffic_type=detect_traffic_type(full_text),
                    volume=detect_volume(full_text)
                )
                buyers.append(buyer)
                
            except Exception as e:
                continue
    
    return buyers


def calculate_match_score(employer: Employer, buyer: Buyer) -> int:
    """–†–∞—Å—Å—á–∏—Ç–∞—Ç—å score —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è."""
    score = 0
    
    # –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –≤–µ—Ä—Ç–∏–∫–∞–ª–∏ (40 –±–∞–ª–ª–æ–≤)
    if employer.vertical == buyer.vertical:
        score += 40
    elif employer.vertical == 'General' or buyer.vertical == 'General':
        score += 20  # –ß–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
    
    # –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ GEO (30 –±–∞–ª–ª–æ–≤)
    geo_overlap = set(employer.geo) & set(buyer.geo)
    if geo_overlap:
        score += 30
    elif 'Worldwide' in employer.geo or 'Worldwide' in buyer.geo:
        score += 15
    
    # –Ø–∑—ã–∫–æ–≤–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ (20 –±–∞–ª–ª–æ–≤)
    if employer.language == 'üá∫üá¶ UA' and any(kw in buyer.reason_ru.lower() for kw in ['—É–∫—Ä', 'ua', '—à—É–∫–∞—î']):
        score += 20
    elif employer.language == 'üá∑üá∫ RU':
        score += 20  # RU —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π
    else:
        score += 10
    
    # Score –±–∞–π–µ—Ä–∞ (10 –±–∞–ª–ª–æ–≤)
    score += min(10, buyer.score)
    
    return min(100, score)


def generate_match_messages(employer: Employer, buyer: Buyer) -> tuple:
    """–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –º—ç—Ç—á–∞."""
    
    # –°–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è —Ä–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª—è
    buyer_info = []
    if buyer.traffic_type:
        buyer_info.append(f"–ª—å—ë—Ç {buyer.traffic_type}")
    if buyer.volume:
        buyer_info.append(f"–æ–±—ä—ë–º {buyer.volume}")
    if buyer.vertical != 'General':
        buyer_info.append(f"–æ–ø—ã—Ç –≤ {buyer.vertical}")
    if buyer.geo and buyer.geo[0] != 'Worldwide':
        buyer_info.append(f"GEO: {', '.join(buyer.geo)}")
    
    buyer_desc = ", ".join(buyer_info) if buyer_info else "–∞–∫—Ç–∏–≤–Ω—ã–π –±–∞–π–µ—Ä —Å –æ–ø—ã—Ç–æ–º"
    
    msg_employer = f"""–ü—Ä–∏–≤–µ—Ç! üëã

–£–≤–∏–¥–µ–ª, —á—Ç–æ –∏—â–µ—Ç–µ –±–∞–π–µ—Ä–∞. –£ –º–µ–Ω—è –µ—Å—Ç—å –∫–∞–Ω–¥–∏–¥–∞—Ç –ø–æ–¥ –≤–∞—à –∑–∞–ø—Ä–æ—Å:

üìå {buyer.display_name or buyer.contact}
‚Ä¢ {buyer_desc}
‚Ä¢ Score: {buyer.score}/10
‚Ä¢ –û–ø–∏—Å–∞–Ω–∏–µ: {buyer.reason_ru[:100]}

–ö–æ–Ω—Ç–∞–∫—Ç: {buyer.contact}

–ú–æ–≥—É –æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞—Ç—å —Å–≤—è–∑—å, –µ—Å–ª–∏ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ. ü§ù"""

    # –°–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –±–∞–π–µ—Ä–∞
    conditions_text = employer.conditions if employer.conditions != "–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ" else "—Ö–æ—Ä–æ—à–∏–µ —É—Å–ª–æ–≤–∏—è"
    
    msg_buyer = f"""–ü—Ä–∏–≤–µ—Ç! üëã

–ù–∞—à—ë–ª —Ç–∏–º–ª–∏–¥–∞ –ø–æ–¥ —Ç–≤–æ–π –ø—Ä–æ—Ñ–∏–ª—å:

üìå {employer.contact}
‚Ä¢ –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {employer.category}
‚Ä¢ –£—Å–ª–æ–≤–∏—è: {conditions_text}
‚Ä¢ {employer.language}

–û–ø–∏—Å–∞–Ω–∏–µ: {employer.reason[:100]}

–ï—Å–ª–∏ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ ‚Äî –º–æ–≥—É –¥–∞—Ç—å –∫–æ–Ω—Ç–∞–∫—Ç. üöÄ"""

    return msg_employer, msg_buyer


def find_matches(employers: List[Employer], buyers: List[Buyer], min_score: int = 50) -> List[Match]:
    """–ù–∞–π—Ç–∏ –≤—Å–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è."""
    matches = []
    
    for employer in employers:
        employer_matches = []
        
        for buyer in buyers:
            match_score = calculate_match_score(employer, buyer)
            
            if match_score >= min_score:
                msg_emp, msg_buy = generate_match_messages(employer, buyer)
                
                match = Match(
                    employer=employer,
                    buyer=buyer,
                    match_score=match_score,
                    match_reason=f"Vertical: {employer.vertical}‚Üî{buyer.vertical}, GEO overlap",
                    message_to_employer=msg_emp,
                    message_to_buyer=msg_buy
                )
                employer_matches.append(match)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ score –∏ –±–µ—Ä—ë–º —Ç–æ–ø-3 –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ä–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª—è
        employer_matches.sort(key=lambda x: x.match_score, reverse=True)
        matches.extend(employer_matches[:3])
    
    return matches


def main():
    print("üîÑ Aura Lead Hunter - AI Matching Engine")
    print("=" * 50)
    
    data_dir = Path('data')
    
    # –ò—â–µ–º —Ñ–∞–π–ª—ã
    employer_files = list(data_dir.glob('ALL_EMPLOYERS_*.txt'))
    buyer_files = [f for f in data_dir.glob('leads_*.csv') if 'export' not in f.name]
    
    if not employer_files:
        print("‚ùå No employer files found!")
        return
    
    if not buyer_files:
        # Fallback to leads_export
        buyer_files = list(data_dir.glob('leads_export.csv'))
        if not buyer_files:
            print("‚ùå No buyer CSV files found!")
            return
    
    # –ë–µ—Ä—ë–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Ñ–∞–π–ª—ã
    employer_file = sorted(employer_files)[-1]
    buyer_file = sorted(buyer_files)[-1]
    
    print(f"üìÇ Employers: {employer_file.name}")
    print(f"üìÇ Buyers: {buyer_file.name}")
    
    # –ü–∞—Ä—Å–∏–º –¥–∞–Ω–Ω—ã–µ
    employers = parse_employers(employer_file)
    buyers = parse_buyers(buyer_file)
    
    print(f"\nüìä Loaded: {len(employers)} employers, {len(buyers)} buyers")
    
    # –ù–∞—Ö–æ–¥–∏–º –º—ç—Ç—á–∏
    matches = find_matches(employers, buyers, min_score=40)
    
    print(f"üéØ Found {len(matches)} matches")
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á—ë—Ç
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = data_dir / f"MATCHES_{timestamp}.txt"
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("# " + "=" * 60 + "\n")
        f.write("# üéØ AURA LEAD HUNTER - AI MATCHING REPORT\n")
        f.write(f"# Generated: {datetime.now().strftime('%d.%m.%Y %H:%M')}\n")
        f.write(f"# Total matches: {len(matches)}\n")
        f.write("# " + "=" * 60 + "\n\n")
        
        # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ä–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª–∏ —Å –º—ç—Ç—á–∞–º–∏
        unique_employers = {}
        for m in matches:
            if m.employer.contact not in unique_employers:
                unique_employers[m.employer.contact] = []
            unique_employers[m.employer.contact].append(m)
        
        f.write(f"# üìã Summary: {len(unique_employers)} employers matched with buyers\n\n")
        
        # –î–µ—Ç–∞–ª—å–Ω—ã–µ –º—ç—Ç—á–∏ –ø–æ —Ä–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª—è–º
        for emp_contact, emp_matches in unique_employers.items():
            f.write("\n" + "‚îÄ" * 60 + "\n")
            emp = emp_matches[0].employer
            f.write(f"# üè¢ EMPLOYER: {emp_contact}\n")
            f.write(f"# Category: {emp.category} | {emp.language}\n")
            f.write(f"# Looking for: {emp.reason[:80]}\n")
            f.write(f"# Conditions: {emp.conditions}\n")
            f.write(f"# Matched buyers: {len(emp_matches)}\n")
            f.write("‚îÄ" * 60 + "\n\n")
            
            for i, m in enumerate(emp_matches, 1):
                f.write(f"## Match #{i} ‚Äî Score: {m.match_score}/100\n")
                f.write(f"## Buyer: {m.buyer.contact} ({m.buyer.display_name})\n")
                f.write(f"## Vertical: {m.buyer.vertical} | Traffic: {m.buyer.traffic_type}\n")
                f.write(f"## {m.buyer.reason_ru[:100]}\n\n")
                
                f.write("### üì§ MESSAGE TO EMPLOYER:\n")
                f.write("```\n")
                f.write(m.message_to_employer)
                f.write("\n```\n\n")
                
                f.write("### üì§ MESSAGE TO BUYER:\n")
                f.write("```\n")
                f.write(m.message_to_buyer)
                f.write("\n```\n\n")
        
        # Quick contacts section
        f.write("\n\n" + "=" * 60 + "\n")
        f.write("# üìã QUICK CONTACT PAIRS\n")
        f.write("=" * 60 + "\n\n")
        
        for emp_contact, emp_matches in unique_employers.items():
            f.write(f"üè¢ {emp_contact} ‚Üí ")
            buyer_contacts = [m.buyer.contact for m in emp_matches]
            f.write(", ".join(buyer_contacts) + "\n")
    
    print(f"\n‚úÖ Report saved: {output_file}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–µ–≤—å—é
    print("\n" + "=" * 50)
    print("üìã TOP MATCHES:")
    print("=" * 50)
    
    for i, (emp_contact, emp_matches) in enumerate(list(unique_employers.items())[:5], 1):
        emp = emp_matches[0].employer
        print(f"\n{i}. {emp_contact} ({emp.category})")
        print(f"   Looking for: {emp.reason[:50]}...")
        for m in emp_matches[:2]:
            print(f"   ‚Üí {m.buyer.contact} (Score: {m.match_score}) - {m.buyer.vertical}")


if __name__ == "__main__":
    main()
