import csv
import re
from pathlib import Path

# --- CONFIGURATION ---
DATA_DIR = Path(r"d:\Aura Lead Hunter\data")
OUTPUT_FILE = DATA_DIR / "AURA_BLACKLIST_WARNINGS.md"

# Negative Keywords
BAD_KEYWORDS = [
    r"scam", r"fraud", r"shave", r"fake", r"liar", r"dishonest", r"stolen", 
    r"warning", r"blacklist", r"thief", r"hack", r"spam",
    r"ÑÐºÐ°Ð¼", r"Ð¼Ð¾ÑˆÐµÐ½Ð½Ð¸Ðº", r"ÐºÐ¸Ð´Ð°Ð»Ð°", r"ÑˆÐµÐ¹Ð²", r"Ð¾Ð±Ð¼Ð°Ð½", r"ÐºÐ¸Ð´Ð¾Ðº", r"Ð¾Ñ‚Ð·Ñ‹Ð²", r"Ð±Ð»ÐµÐºÐ»Ð¸ÑÑ‚"
]

def create_blacklist():
    warnings = []
    csv_files = list(DATA_DIR.glob("*.csv"))
    
    unique_warnings = {}

    for csv_file in csv_files:
        try:
            with open(csv_file, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    msg = row.get('message_preview', '').lower()
                    summary = row.get('ai_summary_ru', row.get('ai_summary_en', '')).lower()
                    handle = row.get('telegram_handle', row.get('user_id', 'Unknown'))
                    
                    full_context = f"{msg} {summary}"
                    
                    found_keywords = [k for k in BAD_KEYWORDS if re.search(k, full_context)]
                    
                    # NEW: Add ID Age check to Risk Detection
                    is_new_account = False
                    try:
                        uid_int = int(row.get('user_id', 0))
                        if uid_int > 7000000000:
                            is_new_account = True
                    except:
                        pass

                    if found_keywords or is_new_account:
                        try:
                            score = int(row.get('score', 5))
                        except:
                            score = 5
                            
                        if handle not in unique_warnings:
                            # Higher risk if new account AND has bad keywords
                            risk_level = "LOW"
                            if is_new_account: risk_level = "MEDIUM (New Acc)"
                            if found_keywords: risk_level = "WARNING"
                            if is_new_account and found_keywords: risk_level = "CRITICAL"
                            if score <= 3: risk_level = "HIGH RISK"

                            unique_warnings[handle] = {
                                'handle': handle,
                                'score': score,
                                'risk': risk_level,
                                'keywords': ", ".join(found_keywords) if found_keywords else "New Account",
                                'summary': row.get('ai_summary_ru', row.get('ai_summary_en', 'No summary')),
                                'uid': row.get('user_id', '0')
                            }

        except Exception as e:
            continue

    # Save to Markdown
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        f.write("# ðŸ›¡ï¸ Aura Security: Anti-Scam & Blacklist Report\n")
        f.write("Generated by Aura AI based on message patterns and keywords.\n\n")
        f.write("| Handle | Score | Risk Factor | AI Summary / Reason |\n")
        f.write("| :--- | :--- | :--- | :--- |\n")
        
        sorted_list = sorted(unique_warnings.values(), key=lambda x: x['score'])
        for w in sorted_list:
            risk = "HIGH" if w['score'] <= 2 else "MEDIUM"
            f.write(f"| **{w['handle']}** | {w['score']}/10 | [{risk}] {w['keywords']} | {w['summary']} |\n")

    print(f"Scanned {len(csv_files)} files. Found {len(unique_warnings)} potential warnings.")
    print(f"Report saved to: {OUTPUT_FILE}")

if __name__ == "__main__":
    create_blacklist()
